{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bbd32",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastapi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastAPI, UploadFile, File, HTTPException\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Unstructured & LangChain imports\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastapi'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "from typing import List\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Unstructured & LangChain imports\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.documents.elements import CompositeElement, Table, Image\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "app = FastAPI(title=\"Multi-PDF RAG API\")\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Hello World! Your API is working.\"}\n",
    "# --- Configuration ---\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCJyUMcF4AIb2p0QmOIY0Tpmo5zfSk96ng\"\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# Global vectorstore to persist across requests (for demo purposes)\n",
    "vectorstore = None\n",
    "retriever = None\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    question: str\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def process_pdf(file_path: str):\n",
    "    \"\"\"Partitions PDF into text, tables, and images.\"\"\"\n",
    "    chunks = partition_pdf(\n",
    "        filename=file_path,\n",
    "        infer_table_structure=True,\n",
    "        strategy=\"hi_res\",\n",
    "        extract_image_block_types=[\"Image\", \"Table\"],\n",
    "        extract_image_block_to_payload=True,\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=10000,\n",
    "        combine_text_under_n_chars=2000,\n",
    "        new_after_n_chars=6000,\n",
    "    )\n",
    "    \n",
    "    texts = [el for el in chunks if isinstance(el, CompositeElement)]\n",
    "    tables = [el for el in chunks if isinstance(el, Table)]\n",
    "    images = [el.metadata.image_base64 for el in chunks if isinstance(el, Image) and el.metadata.image_base64]\n",
    "    \n",
    "    return texts, tables, images\n",
    "\n",
    "def create_documents(texts, tables, images):\n",
    "    \"\"\"Generates summaries and creates LangChain Documents.\"\"\"\n",
    "    docs = []\n",
    "    \n",
    "    # Process Text\n",
    "    for t in texts:\n",
    "        summary = model.invoke(f\"Summarize this text: {t.text}\").content\n",
    "        docs.append(Document(page_content=summary, metadata={\"type\": \"text\", \"original\": t.text}))\n",
    "    \n",
    "    # Process Tables\n",
    "    for t in tables:\n",
    "        summary = model.invoke(f\"Summarize this table: {t.metadata.text_as_html}\").content\n",
    "        docs.append(Document(page_content=summary, metadata={\"type\": \"table\", \"original\": t.metadata.text_as_html}))\n",
    "    \n",
    "    # Process Images\n",
    "    for b64 in images:\n",
    "        msg = model.invoke([\n",
    "            HumanMessage(content=[\n",
    "                {\"type\": \"text\", \"text\": \"Describe this technical diagram in detail.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\"}}\n",
    "            ])\n",
    "        ])\n",
    "        docs.append(Document(page_content=msg.content, metadata={\"type\": \"image\", \"b64\": b64}))\n",
    "        \n",
    "    return docs\n",
    "\n",
    "# --- Endpoints ---\n",
    "\n",
    "@app.post(\"/upload-pdfs/\")\n",
    "async def upload_pdfs(files: List[UploadFile] = File(...)):\n",
    "    global vectorstore, retriever\n",
    "    \n",
    "    if len(files) < 3 or len(files) > 5:\n",
    "        raise HTTPException(status_code=400, detail=\"Please upload between 3 and 5 PDFs.\")\n",
    "\n",
    "    all_docs = []\n",
    "    \n",
    "    for file in files:\n",
    "        temp_file = f\"temp_{file.filename}\"\n",
    "        with open(temp_file, \"wb\") as buffer:\n",
    "            shutil.copyfileobj(file.file, buffer)\n",
    "        \n",
    "        try:\n",
    "            # 1. Partition\n",
    "            texts, tables, images = process_pdf(temp_file)\n",
    "            # 2. Summarize and Create Docs\n",
    "            new_docs = create_documents(texts, tables, images)\n",
    "            all_docs.extend(new_docs)\n",
    "        finally:\n",
    "            if os.path.exists(temp_file):\n",
    "                os.remove(temp_file)\n",
    "\n",
    "    # 3. Build/Update Vectorstore\n",
    "    if vectorstore is None:\n",
    "        vectorstore = FAISS.from_documents(all_docs, embeddings)\n",
    "    else:\n",
    "        vectorstore.add_documents(all_docs)\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    return {\"message\": f\"Successfully processed {len(files)} files and updated the index.\"}\n",
    "\n",
    "@app.post(\"/query/\")\n",
    "async def query_rag(request: QueryRequest):\n",
    "    if retriever is None:\n",
    "        raise HTTPException(status_code=400, detail=\"No documents uploaded yet.\")\n",
    "    \n",
    "    relevant_docs = retriever.invoke(request.question)\n",
    "    \n",
    "    context = \"\"\n",
    "    for doc in relevant_docs:\n",
    "        if doc.metadata[\"type\"] == \"text\":\n",
    "            context += f\"\\n[TEXT]: {doc.metadata['original']}\"\n",
    "        elif doc.metadata[\"type\"] == \"table\":\n",
    "            context += f\"\\n[TABLE]: {doc.metadata['original']}\"\n",
    "        elif doc.metadata[\"type\"] == \"image\":\n",
    "            context += f\"\\n[IMAGE DESCRIPTION]: {doc.page_content}\"\n",
    "\n",
    "    prompt = f\"Answer the question using ONLY the context provided.\\nContext: {context}\\nQuestion: {request.question}\"\n",
    "    answer = model.invoke(prompt).content\n",
    "    \n",
    "    return {\"question\": request.question, \"answer\": answer}\n",
    "\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
